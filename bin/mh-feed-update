#!/usr/bin/env python2.6
# Get feeds from list in ~/.feeds and file them into nmh folders
import os
import feedparser
from thread import start_new_thread
from urlparse import urlparse
from subprocess import Popen, PIPE
from email.utils import formatdate
from time import mktime

# Get a pickle library
try:
    import cPickle as pickle
except ImportError:
    import pickle

# Configuration
FEEDLIST_PATH= os.environ["HOME"]+"/.feeds"
SEEN_PATH = os.environ["HOME"]+"/.feeds.seen"
MH_FOLDER = "feed"
VERBOSE = True

# Listed feeds
Feeds = []

# Seen cache
Seen = {}
if os.path.exists(SEEN_PATH):
    with open(SEEN_PATH, 'rb') as fd:
        Seen = pickle.load(fd)

# Get all feeds
with open(FEEDLIST_PATH) as fd:
    for line in fd:
        line = line.strip()
        if not line.startswith("#") and line:
            Feeds.append(line.strip().split())

def feed_parse(name, feed):
    if VERBOSE:
        print("Synchronising feed: "+str(feed))

    # Parse feed
    data = feedparser.parse(feed)

    # Create seen list
    if name not in Seen:
        Seen[name] = {}

    # Get the absolute folder
    folder_pipe = Popen(["mhpath", "+%s/%s" % (MH_FOLDER, name)],
                 close_fds=True, stdout=PIPE)
    folder = folder_pipe.stdout.readline().strip()
    folder_pipe.stdout.close()

    # Make sure the folder exists
    if not os.path.exists(folder):
        os.makedirs(folder)

    # Get last used number
    last = Popen(["mhpath", "+%s/%s" % (MH_FOLDER, name), "last"],
                 close_fds=True, stdout=PIPE)

    try:
        num = int(last.stdout.readline())+1
    except ValueError:
        num = 1
    last.stdout.close()

    # Keep track of all added
    unseen = []

    # Add all entries
    for entry in data["entries"]:
        if entry["title"] not in Seen[name]:
            # Create mailbox file
            with open(os.path.join(folder, str(num)), "w") as mfile:
                if VERBOSE:
                    print("  New entry in "+name+": "+entry["title"])

                # Mark entry as seen
                Seen[name][entry["title"]] = True

                # File entry into mailbox
                write_utf8 = lambda st: mfile.write(st.encode("utf-8"))

                # Write link on first line
                write_utf8(entry["link"]+"\n")

                # Write headers
                write_utf8("From: %s <%s>\n" % (data["feed"]["title"], feed))
                write_utf8("Subject: %s\n" % entry["title"])

                if "updated_parsed" in entry:
                    write_utf8("Date: %s\n" % formatdate(mktime(entry["updated_parsed"])))
                else:
                    write_utf8("Date: %s\n" % formatdate())

                if "content" in entry and entry["content"]:
                    write_utf8("\n"+entry["content"][0]["value"])
                elif "summary_detail" in entry:
                    write_utf8("\n"+entry["summary_detail"]["value"])
                elif "summary" in entry:
                    write_utf8("\n"+entry["summary"]["value"])
                else:
                    write_utf8("\nNo content detected...")

                num += 1

            # Add to unseen list
            unseen.append(str(num))

    # Save unseen sequence
    seqpath = os.path.join(folder, ".mh_sequences")
    if os.path.exists(seqpath):
        with open(seqpath, "r") as seq:
            lines = seq.readlines()
            for i, line in enumerate(lines):
                if line.startswith("unseen: "):
                    unseen.extend(line[8:].split())
                    lines[i] = "unseen: "+" ".join(unseen)

        with open(seqpath, "w") as seq:
            seq.writelines(lines)
    else:
        with open(seqpath, "w") as seq:
            line = "unseen: "+" ".join(unseen)
            seq.writelines([line])

# Sync all feeds
for name, feed in Feeds:
    feed_parse(name, feed)

# Save seen cache
with open(SEEN_PATH, 'wb') as fd:
    pickle.dump(Seen, fd, pickle.HIGHEST_PROTOCOL)
